# Batch gradient descent 批量梯度下降（BGD）

在梯度下降的每一步都使用**全部**的训练用例

$ \theta = \theta - \alpha·\frac{\partial}{\partial \theta}J(\theta)$​

- $\theta$ 是要训练的参数

# Stochastic Gradient Descent  随机梯度下降（SGD）

每读入一个数据（example）就立刻更新参数

$ \theta = \theta - \alpha · \frac{\partial}{\partial \theta}J(\theta,(x^{(i)},y^{(i)})) $

# Mini-batch Gradient Descent 小批量梯度下降（MBGD）

每次利用一小批样本

$ \theta = \theta - \alpha · \frac{\partial}{\partial \theta}J(\theta,(x^{(i:i+n)},y^{(i:i+n)})) $

# Momentum 

物体运动有惯性

$ v_t = \gamma·v_{t-1} + \alpha·\frac{\partial}{\partial \theta}J(\theta) $

$\theta_{t+1} = \theta_{t} - v_t$

- $\gamma \in (0,1)$​ 是阻力,通常取0.9
- $ \gamma · v_{t-1} $ 惯性

# Nesterov Momentum



$ v_t = \gamma·v_{t-1} + \alpha·\frac{\partial}{\partial \theta}J(\theta + \gamma·v_{t-1}) $

$\theta_{t+1} = \theta_{t} - v_t$